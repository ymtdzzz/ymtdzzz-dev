---
title: "インターン生の研修環境をTerraformとcloud9でサクッと作った話"
date: 2021-06-03
tags:
  - "Terraform"
  - "AWS"
  - "cloud9"
published: True
category: Infrastructure
---

所属会社にて、内定者向けのインターン（っていうのか？）を開催することになり、急遽環境構築をすることになりました。

内容も結構本格的で、ほぼ実案件のソースを使ってバグ改修とか機能追加とかさせたいね　ということでした。まあソースとかは一応持ち帰りで作ってる案件のソースもあるし、バグについても過去のバグチケットを漁れば良いな　と。

あとはただ一つ、インターン担当者の思いは...

<!--more-->

**出社したくねえ...＼(^o^)／**

ということで、準備ももちろん、実施もオンラインでも対応できるような形を目指して環境構築がスタートしましたとさ。


## 作った環境 {#作った環境}


### 要件 {#要件}

-   ブラウザ経由でソースコードの編集、及び動作確認ができること
-   **セキュアであること**
-   環境構築が簡単なこと


### ソースコード {#ソースコード}

Terraformで作ってGithubに置いておきました。

[Github/zeroclock - cloud9-training-env-terraform](https://github.com/zeroclock/cloud9-training-env-terraform)


### 構成図 {#構成図}

ざっくりとこんな感じの環境を作りました。

![](../../../../gridsome-flex-markdown-starter/src/assets/images/old/ox-hugo/06-03-overview.svg)

### 構成について {#構成について}

クラウド上でIDEを使うとなると、個人的にはCloud9一択でした。とはいえ、数年前に勉強のためにちょろっと触ったくらいだったので、何ができるかについては若干手探りで。

最近Cloud9がSystemsManager経由で利用可能になった（≒プライベートサブネットで利用可能になった）という話を聞いており、パブリックにインスタンスを置かなくても良さそうだったという部分も後押しになった形。

> 注意ですが、[この記事](https://dev.classmethod.jp/articles/cloud9-ide-network-condition/)にあるように、AWS側としてはプライベートサブネットではなく「インバウンド通信を遮断した（no-ingressな）パブリックサブネット」での利用を意図しているようですね。ただ、今回は特にaws cliを使ったりしないためプライベートサブネット上に構築しました。

また、できるだけ簡単に環境構築ができるように、「作成するIAMユーザの数」と「作成する環境の数」を変数化して、動的に変更できるようにしました。

というのも、まだ具体的な参加人数が決まっていないため、実際の環境構築時にダイナミックに変更可能にしたかったためです。

ソースコードだとこの辺です。

<https://github.com/zeroclock/cloud9-training-env-terraform/blob/master/user/main.tf>

```terraform
resource "aws_iam_user" "this" {
    count = var.user_count
    name = "${var.name}-${count.index}"
    path = "/"
    force_destroy = true
}
```

<div class="src-block-caption">
  <span class="src-block-number">Code 1</span>:
  TerraformによるIAMユーザの動的な変更
</div>

また、今回はCloud9のインスタンス内でDockerコンテナを起動して、それをlocalhostで見に行く感じになりますので、クラウド上でローカル開発環境を作るようなイメージです。

（いくつかハマりポイントがありますので後述します）


## 構築フロー {#構築フロー}

今回はTerraformを使用したので、かなり簡単に環境の作成＆削除が行えます。

具体的な構築手順は下記の通り。

![](../../../../gridsome-flex-markdown-starter/src/assets/images/old/ox-hugo/06-03-overview2.svg)

インフラの手動構築（AWSのコンソールでのポチポチ）は不要ですが、各環境内部で実施する作業は、 ~~自動化する時間がありませんでした~~ 自動化しませんでした。

-   Gitからの研修用ソースのPull：これはCodeCommitのみ対応なので、今回はどちらにしても無理だった
-   dockerイメージのビルド：ECRにイメージPushでそれをPullでいいかも
-   依存パッケージのインストール
-   env系の修正


## ハマりポイント {#ハマりポイント}


### プレビューが表示されない {#プレビューが表示されない}

プレビューでアクセスする際のポートは8080にしないと死にます（噂によると8081,8082とかも大丈夫らしいけど8080にしといた方が無難）


### セッションが死ぬ {#セッションが死ぬ}

デバッグログで見るとわかりますが、envとかの設定でcookie発行時のドメイン情報がlocalhostのままになってたりすると、3rd-party cookieで弾かれます。ログインできなくて若干ハマりました。


### localhostじゃないのでドメイン設定に気をつける {#localhostじゃないのでドメイン設定に気をつける}

プレビューを表示すると、ドメインがhogehoge.vfs~みたいな構成になってますので、そのドメイン名をアプリ側にも設定しておきます（Cookieの件と似てますね）


## さいごに {#さいごに}

そんな感じで作ってみた環境ですが、t2.smallとかのインスタンスでもわりと快適に動いてますので、意外と使い所多いかも？と思いました。

ただ、一点注意なんですが、プライベートサブネットなのでインターネット通信のためにNAT GWが必要です。

NAT GWは利用料金が跳ね上がる原因の上位にランクインするやばいやつなので、ご利用は計画的に・・・。（多分一ヶ月起動しっぱとかだとインスタンス諸々含め2万くらいとられます...）
